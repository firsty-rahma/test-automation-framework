# Selenium WebDriver Test Automation Framework

[![Selenium Tests](https://github.com/yourusername/test-automation-framework/actions/workflows/selenium-tests.yml/badge.svg)](https://github.com/yourusername/test-automation-framework/actions/workflows/selenium-tests.yml)
[![Python](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Selenium](https://img.shields.io/badge/selenium-4.15+-green.svg)](https://www.selenium.dev/)
[![Tests](https://img.shields.io/badge/tests-13%20passing-brightgreen)](https://github.com/yourusername/test-automation-framework)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

A production-ready test automation framework demonstrating industry best practices for web UI testing. Built with Selenium WebDriver, Page Object Model design pattern, and comprehensive CI/CD integration.

> **Development Approach**: This project showcases modern software development practices, utilizing AI tools (Claude Sonnet 4.5) for code optimization and architectural guidance, following industry standards where developers leverage AI alongside traditional resources for enhanced productivity and code quality.

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Key Features](#-key-features)
- [Architecture](#-architecture)
- [Getting Started](#-getting-started)
- [Running Tests](#-running-tests)
- [Screenshot on Failure](#-screenshot-on-failure)
- [CI/CD Integration](#-cicd-integration)
- [Test Organization](#-test-organization)
- [Test Coverage](#-test-coverage)
- [Configuration](#-configuration)
- [Technical Stack](#-technical-stack)
- [Project Structure](#-project-structure)
- [Best Practices](#-best-practices)
- [Contributing](#-contributing)

---

## ğŸ¯ Overview

This framework demonstrates comprehensive test automation capabilities with:

- **13 Automated Test Cases** covering critical UI workflows
- **Page Object Model (POM)** for maintainable, scalable test architecture
- **Automated Screenshot Capture** on test failures for rapid debugging
- **CI/CD Pipeline** with GitHub Actions for continuous testing
- **HTML Reporting** with embedded screenshots and detailed metrics
- **Professional Code Organization** following industry best practices

**Test Site**: [the-internet.herokuapp.com](https://the-internet.herokuapp.com) - A dedicated automation practice site

---

## âœ¨ Key Features

### 1. Page Object Model Architecture

**Design Pattern Implementation:**
- Separation of page logic from test logic for enhanced maintainability
- Reusable `BasePage` class with common web interaction methods
- Individual page classes for each application page/feature
- Eliminates code duplication and improves test readability

**Benefits:**
- âœ… Easy maintenance when UI changes
- âœ… Reusable components across multiple tests
- âœ… Clear abstraction layers
- âœ… Scalable for growing test suites

### 2. Screenshot on Failure ğŸ“¸

**Automatic failure capture system** that enhances debugging efficiency:

**How It Works:**
```
Test Execution â†’ Test Fails â†’ pytest Hook Triggered â†’ Screenshot Captured
                                                     â†“
                                    Saved to screenshots/ directory
                                                     â†“
                                    Embedded in HTML report
                                                     â†“
                                    Uploaded to CI/CD artifacts
```

**Features:**
- âœ… Automatic screenshot capture on any test failure
- âœ… Unique filename with timestamp and test name
- âœ… Screenshots embedded directly in HTML reports
- âœ… Uploaded as CI/CD artifacts (7-day retention)
- âœ… Local storage in `screenshots/` directory

**Screenshot Naming Convention:**
```
tests_test_with_pom.py_TestCheckboxes_test_checkboxes_toggle_20241224_143022.png
â”‚                      â”‚                â”‚                      â”‚
â”‚                      â”‚                â”‚                      â””â”€ Timestamp (YYYYMMDD_HHMMSS)
â”‚                      â”‚                â””â”€ Test method name
â”‚                      â””â”€ Test class name
â””â”€ Test file path
```

**Viewing Screenshots:**

**Local Development:**
```bash
# After test failure
ls screenshots/

# View most recent screenshot
open screenshots/$(ls -t screenshots/ | head -1)  # Mac
start screenshots/$(ls -t screenshots/ | head -1)  # Windows
```

**CI/CD (GitHub Actions):**
1. Navigate to **Actions** tab
2. Click on failed workflow run
3. Scroll to **Artifacts** section
4. Download `failure-screenshots.zip`

**HTML Reports:**
- Screenshots automatically embedded in test failure details
- Click screenshot for full-size view
- Hover for additional metadata

### 3. Comprehensive Test Coverage

**UI Interaction Tests:**
- Dynamic element manipulation (Add/Remove)
- Form controls (Dropdowns, Checkboxes)
- Keyboard input detection and validation
- Context menu (right-click) interactions

**File Operations:**
- File upload with validation
- File download with integrity verification
- Temporary file handling

**Advanced Scenarios:**
- HTTP Basic Authentication
- Multiple window/tab management
- HTTP status code validation (200, 404, 500)

### 4. Professional Test Organization

**Pytest Markers** for flexible test execution:

```python
@pytest.mark.smoke      # Critical path tests - run first
@pytest.mark.regression # Full test suite - comprehensive coverage
@pytest.mark.ui         # User interface interaction tests
@pytest.mark.slow       # Tests requiring longer execution (>5s)
@pytest.mark.download   # File download operations
@pytest.mark.upload     # File upload operations
@pytest.mark.windows    # Multiple window handling
```

**Benefits:**
- Run critical tests first for fast feedback
- Execute specific test categories as needed
- Exclude slow tests during rapid development
- Organize tests by feature or risk level

### 5. Robust Wait Strategies

**Multiple wait mechanisms** for reliable test execution:

- **Explicit Waits**: Custom conditions for specific elements
- **Implicit Waits**: Global timeout for element location
- **Smart Waits**: Dynamic waits for AJAX and async operations
- **Custom Wait Functions**: Specialized conditions for complex scenarios

**Example Wait Implementations:**
```python
# Explicit wait for element clickability
wait.until(EC.element_to_be_clickable((By.ID, "submit-button")))

# Custom wait for file download completion
wait.until(lambda d: len(os.listdir(download_dir)) > 0)

# Wait for page title
wait.until(EC.title_is("Expected Page Title"))
```

---

## ğŸ—ï¸ Architecture

### Page Object Model Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Test Layer                            â”‚
â”‚  (test_with_pom.py - Test Classes & Methods)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Page Object Layer                       â”‚
â”‚  (HomePage, DropdownPage, CheckboxesPage, etc.)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Base Page Layer                        â”‚
â”‚  (BasePage - Common methods & utilities)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Selenium WebDriver                       â”‚
â”‚  (Browser automation & interaction)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Design Principles

1. **Separation of Concerns**: Test logic separated from page interaction logic
2. **DRY (Don't Repeat Yourself)**: Common methods centralized in BasePage
3. **Single Responsibility**: Each page class handles only its page's elements
4. **Encapsulation**: Page elements and actions hidden from tests
5. **Maintainability**: UI changes require updates only in page objects

---

## ğŸš€ Getting Started

### Prerequisites

| Requirement | Minimum Version | Purpose |
|-------------|----------------|---------|
| Python | 3.9+ | Runtime environment |
| pip | Latest | Package management |
| Chrome | Latest | Test browser |
| Git | Latest | Version control |

### Installation

**1. Clone the repository:**
```bash
git clone https://github.com/yourusername/test-automation-framework.git
cd test-automation-framework
```

**2. Create and activate virtual environment:**

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

**Mac/Linux:**
```bash
python3 -m venv venv
source venv/bin/activate
```

**3. Install dependencies:**
```bash
pip install -r requirements.txt
```

**4. Verify installation:**
```bash
# Check Python version
python --version

# Check Selenium installation
python -c "import selenium; print(f'Selenium {selenium.__version__} installed')"

# Verify page objects import
python -c "from pages.home_page import HomePage; print('âœ… Page objects working')"
```

**5. Create necessary directories:**
```bash
mkdir -p reports screenshots
```

### Quick Start

**Run a single smoke test:**
```bash
pytest tests/test_with_pom.py::TestBasicAuth::test_basic_auth_success -v
```

**Expected output:**
```
tests/test_with_pom.py::TestBasicAuth::test_basic_auth_success PASSED [100%]
======================== 1 passed in 3.42s ========================
```

---

## ğŸ§ª Running Tests

### Basic Execution

```bash
# Run all tests
pytest tests/test_with_pom.py -v

# Run all tests with detailed output
pytest tests/test_with_pom.py -vv

# Run with print statements visible
pytest tests/test_with_pom.py -v -s
```

### Generate HTML Report

```bash
# Generate comprehensive HTML report
pytest tests/test_with_pom.py --html=reports/report.html --self-contained-html

# Then open the report
# Mac: open reports/report.html
# Windows: start reports/report.html
# Linux: xdg-open reports/report.html
```

**Report Contents:**
- âœ… Test execution summary (pass/fail/skip)
- â±ï¸ Individual test execution times
- ğŸ“Š Total duration and statistics
- ğŸ“¸ Embedded screenshots for failures
- ğŸ“ Error messages and stack traces
- ğŸ·ï¸ Test markers and categories

### Run Tests by Category

```bash
# Quick smoke tests (critical path validation)
pytest -m smoke -v

# Full regression suite
pytest -m regression -v

# Only UI interaction tests
pytest -m ui -v

# File operation tests
pytest -m "download or upload" -v

# Exclude slow tests (for rapid development)
pytest -m "not slow" -v

# Combine multiple markers
pytest -m "smoke and ui" -v
```

### Run Specific Tests

```bash
# Run specific test class
pytest tests/test_with_pom.py::TestCheckboxes -v

# Run specific test method
pytest tests/test_with_pom.py::TestCheckboxes::test_checkboxes_toggle -v

# Run tests matching keyword
pytest -k "checkbox" -v

# Run tests in specific file
pytest tests/test_with_pom.py -v
```

### Advanced Execution Options

```bash
# Stop after first failure
pytest tests/test_with_pom.py -x

# Stop after N failures
pytest tests/test_with_pom.py --maxfail=3

# Run last failed tests only
pytest tests/test_with_pom.py --lf

# Run failed tests first, then others
pytest tests/test_with_pom.py --ff

# Parallel execution (requires pytest-xdist)
pytest tests/test_with_pom.py -n 4  # 4 parallel workers

# Show slowest 5 tests
pytest tests/test_with_pom.py --durations=5
```

### Debugging Tests

```bash
# Drop into debugger on failure
pytest tests/test_with_pom.py --pdb

# Verbose output with print statements
pytest tests/test_with_pom.py -vv -s

# Show local variables on failure
pytest tests/test_with_pom.py -l
```

---

## ğŸ“¸ Screenshot on Failure

### Technical Implementation

**Hook Function (`conftest.py`):**
```python
@pytest.hookimpl(tryfirst=True, hookwrapper=True)
def pytest_runtest_makereport(item, call):
    """Capture screenshots automatically on test failure"""
    outcome = yield
    rep = outcome.get_result()
    
    if rep.when == "call" and rep.failed:
        driver = item.funcargs.get('driver', None)
        if driver:
            # Generate unique filename
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            screenshot_path = f"screenshots/{item.nodeid}_{timestamp}.png"
            
            # Capture and save
            driver.save_screenshot(screenshot_path)
```

### Configuration Options

**Directory Structure:**
```bash
screenshots/
â”œâ”€â”€ tests_test_with_pom.py_TestCheckboxes_test_toggle_20241224_143022.png
â”œâ”€â”€ tests_test_with_pom.py_TestDropdown_test_select_20241224_143045.png
â””â”€â”€ tests_test_with_pom.py_TestFileUpload_test_upload_20241224_143108.png
```

**Customization:**

Change screenshot directory:
```python
# In conftest.py
screenshots_dir = "test_failures"  # Instead of "screenshots"
```

Capture screenshots for all tests (not just failures):
```python
# In conftest.py - remove the 'failed' condition
if rep.when == "call":  # Captures for all tests
    driver.save_screenshot(screenshot_path)
```

### Integration with CI/CD

Screenshots are automatically uploaded as artifacts in GitHub Actions:

**Configuration (`.github/workflows/selenium-tests.yml`):**
```yaml
- name: Upload screenshots on failure
  if: failure()
  uses: actions/upload-artifact@v4
  with:
    name: failure-screenshots
    path: screenshots/
    retention-days: 7
```

**Accessing CI/CD Screenshots:**
1. Go to **Actions** tab in GitHub
2. Click on the failed workflow run
3. Scroll to **Artifacts** section at the bottom
4. Download **failure-screenshots.zip**
5. Extract and view screenshot files

### Best Practices

âœ… **DO:**
- Review screenshots immediately after test failures
- Share screenshots with team members for collaborative debugging
- Keep screenshots in `.gitignore` to avoid repository bloat
- Use descriptive test names for easier screenshot identification

âŒ **DON'T:**
- Commit screenshot files to version control
- Rely solely on screenshots without checking logs
- Ignore screenshot file size (compress if needed)
- Keep old screenshots indefinitely (clean up regularly)

---

## ğŸ”„ CI/CD Integration

### GitHub Actions Workflow

**Automated Testing Pipeline:**

```yaml
Trigger Events:
â”œâ”€â”€ Push to main/develop branch
â”œâ”€â”€ Pull request creation
â”œâ”€â”€ Scheduled (daily at 2 AM UTC)
â””â”€â”€ Manual trigger (workflow_dispatch)

Pipeline Stages:
â”œâ”€â”€ 1. Environment Setup
â”‚   â”œâ”€â”€ Checkout code
â”‚   â”œâ”€â”€ Setup Python 3.11
â”‚   â”œâ”€â”€ Install Chrome browser
â”‚   â””â”€â”€ Install dependencies
â”œâ”€â”€ 2. Test Execution
â”‚   â”œâ”€â”€ Run smoke tests (fast feedback)
â”‚   â””â”€â”€ Run full test suite
â”œâ”€â”€ 3. Artifact Collection
â”‚   â”œâ”€â”€ Upload HTML reports (30-day retention)
â”‚   â””â”€â”€ Upload failure screenshots (7-day retention)
â””â”€â”€ 4. Results Summary
    â””â”€â”€ Generate test summary in GitHub UI
```

**Workflow Configuration:**

Location: `.github/workflows/selenium-tests.yml`

Key features:
- âœ… Automated Chrome/ChromeDriver installation
- âœ… Python dependency caching for faster runs
- âœ… Parallel test execution capability
- âœ… Artifact upload for test reports and screenshots
- âœ… Test summary in GitHub Actions UI

**Viewing Results:**

1. **In GitHub UI:**
   - Go to repository â†’ **Actions** tab
   - Click on workflow run
   - View test summary and artifacts

2. **Email Notifications:**
   - Configure in GitHub Settings â†’ Notifications
   - Get alerts for failed workflow runs

3. **Badge Status:**
   - README badge shows current test status
   - Updates automatically after each run

---

## ğŸ¯ Test Organization

### Test Structure

```
tests/test_with_pom.py
â”œâ”€â”€ TestAddRemoveElements      [1 test]  @smoke @ui
â”œâ”€â”€ TestBasicAuth              [1 test]  @smoke
â”œâ”€â”€ TestDropdown               [2 tests] @regression @ui
â”œâ”€â”€ TestContextMenu            [1 test]  @ui
â”œâ”€â”€ TestFileDownload           [1 test]  @download @slow
â”œâ”€â”€ TestFileUpload             [1 test]  @upload
â”œâ”€â”€ TestStatusCodes            [3 tests] @regression
â”œâ”€â”€ TestCheckboxes             [1 test]  @smoke @ui
â”œâ”€â”€ TestKeyPresses             [1 test]  @ui
â””â”€â”€ TestMultipleWindows        [1 test]  @windows
```

### Marker Definitions

| Marker | Purpose | Test Count | Execution Time |
|--------|---------|------------|----------------|
| `smoke` | Critical path validation | 3 | ~10 seconds |
| `regression` | Comprehensive coverage | 5 | ~30 seconds |
| `ui` | User interface tests | 8 | ~25 seconds |
| `slow` | Tests >5 seconds | 1 | ~20 seconds |
| `download` | File download tests | 1 | ~20 seconds |
| `upload` | File upload tests | 1 | ~5 seconds |
| `windows` | Multi-window tests | 1 | ~8 seconds |

### Recommended Test Execution Strategy

**During Development:**
```bash
# 1. Run smoke tests after each change
pytest -m smoke -v

# 2. Run feature-specific tests
pytest -m ui -v  # If working on UI

# 3. Run all tests before commit
pytest tests/test_with_pom.py -v
```

**Before Release:**
```bash
# 1. Full regression suite
pytest -m regression -v

# 2. All tests with HTML report
pytest tests/test_with_pom.py --html=reports/release-report.html --self-contained-html

# 3. Verify all markers
pytest --markers
```

---

## ğŸ“Š Test Coverage

### Feature Coverage Matrix

| Feature | Test Class | Tests | Status | Priority |
|---------|-----------|-------|--------|----------|
| Dynamic Elements | TestAddRemoveElements | 1 | âœ… | High |
| Authentication | TestBasicAuth | 1 | âœ… | High |
| Form Controls | TestDropdown | 2 | âœ… | High |
| Context Menus | TestContextMenu | 1 | âœ… | Medium |
| File Download | TestFileDownload | 1 | âœ… | High |
| File Upload | TestFileUpload | 1 | âœ… | High |
| HTTP Status | TestStatusCodes | 3 | âœ… | Medium |
| Checkboxes | TestCheckboxes | 1 | âœ… | High |
| Keyboard Input | TestKeyPresses | 1 | âœ… | Medium |
| Window Management | TestMultipleWindows | 1 | âœ… | High |

**Total:** 13 tests | **Passing:** 13 (100%) | **Coverage:** Critical workflows

---

## âš™ï¸ Configuration

### config.py

```python
class Config:
    BASE_URL = "https://the-internet.herokuapp.com"
    TIMEOUT = 10          # Explicit wait timeout (seconds)
    USERNAME = "admin"    # Basic auth username (demo)
    PASSWORD = "admin"    # Basic auth password (demo)
    BROWSER = "chrome"    # Default browser
```

### pytest.ini

```ini
[pytest]
# Test discovery
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Markers
markers =
    smoke: Quick smoke tests
    regression: Full regression tests
    ui: UI interaction tests
    slow: Tests that take longer to run
    download: File download tests
    upload: File upload tests
    windows: Multiple windows tests

# Reporting
addopts = 
    -v
    --tb=short
    --strict-markers
    --html=reports/report.html
    --self-contained-html

# Logging
log_cli = true
log_cli_level = INFO
```

### conftest.py

Centralized pytest configuration:
- **Fixtures**: `driver`, `base_url`
- **Hooks**: Screenshot on failure
- **Setup/Teardown**: Browser lifecycle management

---

## ğŸ› ï¸ Technical Stack

### Core Technologies

| Technology | Version | Purpose |
|------------|---------|---------|
| **Python** | 3.9+ | Programming language |
| **Selenium WebDriver** | 4.15+ | Browser automation |
| **Pytest** | 7.4+ | Testing framework |
| **pytest-html** | 4.1+ | HTML reporting |
| **pytest-xdist** | 3.5+ | Parallel execution |

### Development Tools

- **Git**: Version control
- **Virtual Environment**: Dependency isolation
- **Chrome/ChromeDriver**: Test browser
- **GitHub Actions**: CI/CD platform

### Python Packages

```txt
selenium==4.15.2        # Browser automation
pytest==7.4.3          # Testing framework
pytest-html==4.1.1     # HTML reports
pytest-xdist==3.5.0    # Parallel execution
```

---

## ğŸ“ Project Structure

```
test-automation-framework/
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ selenium-tests.yml         # CI/CD configuration
â”‚
â”œâ”€â”€ pages/                             # Page Object Model
â”‚   â”œâ”€â”€ __init__.py                   # Package initializer
â”‚   â”œâ”€â”€ base_page.py                  # Base page class
â”‚   â”œâ”€â”€ home_page.py                  # Home/navigation page
â”‚   â”œâ”€â”€ add_remove_page.py            # Add/Remove Elements page
â”‚   â”œâ”€â”€ dropdown_page.py              # Dropdown page
â”‚   â”œâ”€â”€ checkboxes_page.py            # Checkboxes page
â”‚   â”œâ”€â”€ context_menu_page.py          # Context menu page
â”‚   â”œâ”€â”€ file_download_page.py         # File download page
â”‚   â”œâ”€â”€ file_upload_page.py           # File upload page
â”‚   â”œâ”€â”€ status_codes_page.py          # Status codes page
â”‚   â”œâ”€â”€ key_presses_page.py           # Key presses page
â”‚   â”œâ”€â”€ multiple_windows_page.py      # Multiple windows page
â”‚   â””â”€â”€ basic_auth_page.py            # Basic auth page
â”‚
â”œâ”€â”€ tests/                             # Test suites
â”‚   â”œâ”€â”€ __init__.py                   # Package initializer
â”‚   â”œâ”€â”€ test_with_pom.py              # Main POM-based tests
â”‚   â””â”€â”€ test_basic.py                 # Legacy tests (optional)
â”‚
â”œâ”€â”€ reports/                           # Test reports (generated)
â”‚   â”œâ”€â”€ report.html                   # Latest HTML report
â”‚   â””â”€â”€ *.html                        # Historical reports
â”‚
â”œâ”€â”€ screenshots/                       # Failure screenshots (generated)
â”‚   â””â”€â”€ *.png                         # Screenshot files
â”‚
â”œâ”€â”€ config.py                          # Test configuration
â”œâ”€â”€ conftest.py                        # Pytest fixtures & hooks
â”œâ”€â”€ pytest.ini                         # Pytest configuration
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ .gitignore                         # Git ignore rules
â””â”€â”€ README.md                          # This file
```

---

## ğŸ’¡ Best Practices Demonstrated

### Code Quality
- âœ… **DRY Principle**: No code duplication
- âœ… **SOLID Principles**: Single responsibility, open/closed
- âœ… **PEP 8**: Python style guide compliance
- âœ… **Type Hints**: Clear function signatures (optional)
- âœ… **Docstrings**: Comprehensive documentation

### Test Design
- âœ… **Independent Tests**: No dependencies between tests
- âœ… **Descriptive Names**: Clear test purpose from name
- âœ… **Arrange-Act-Assert**: Clear test structure
- âœ… **Explicit Assertions**: Meaningful failure messages
- âœ… **Setup/Teardown**: Proper test lifecycle management

### Framework Design
- âœ… **Page Object Model**: Separation of concerns
- âœ… **Reusable Components**: BasePage with common methods
- âœ… **Configuration Management**: Centralized settings
- âœ… **Error Handling**: Graceful failure management
- âœ… **Logging**: Comprehensive test execution logs

### DevOps
- âœ… **CI/CD Integration**: Automated testing
- âœ… **Version Control**: Git best practices
- âœ… **Documentation**: Comprehensive README
- âœ… **Artifact Management**: Report and screenshot storage

---

## ğŸ“ Skills Demonstrated

### Technical Skills
- **Test Automation**: Selenium WebDriver, web UI testing
- **Python Programming**: OOP, fixtures, decorators, hooks
- **Design Patterns**: Page Object Model, Factory pattern
- **Testing Frameworks**: Pytest, markers, fixtures, parameterization
- **CI/CD**: GitHub Actions, workflow automation
- **Version Control**: Git, branching, pull requests

### Software Engineering
- **Clean Code**: Readable, maintainable, documented
- **Architecture**: Layered design, separation of concerns
- **Problem Solving**: Handling timing, synchronization, edge cases
- **Documentation**: Technical writing, code comments
- **Best Practices**: Industry standards, coding conventions

### Quality Assurance
- **Test Strategy**: Risk-based testing, smoke vs regression
- **Test Organization**: Markers, categories, priorities
- **Debugging**: Screenshots, logs, error analysis
- **Reporting**: HTML reports, metrics, visualization

---

## ğŸ¤ Contributing

This is a portfolio project demonstrating test automation capabilities. Feedback and suggestions are welcome!

### Suggesting Improvements

1. Open an issue describing the improvement
2. Provide context and rationale
3. Include examples if applicable

### Reporting Bugs

1. Check existing issues first
2. Provide reproduction steps
3. Include error messages and screenshots
4. Specify environment details

---

## ğŸ“„ License

This project is for educational and portfolio purposes.

---

## ğŸ‘¤ Author

**Your Name**
- GitHub: [@firsty-rahma](https://github.com/firsty-rahma)
- LinkedIn: [Firstyani Rahma](https://www.linkedin.com/in/firstyani-rahma-412990236/)
- Email: firsty.rahma9521@gmail.com

---

## ğŸ™ Acknowledgments

- **Test Site**: [the-internet.herokuapp.com](https://the-internet.herokuapp.com) - Excellent automation practice resource
- **Selenium**: WebDriver team for browser automation tools
- **Pytest**: Testing framework community
- **AI Assistance**: Claude Sonnet 4.5 for code optimization and architectural guidance

---

## ğŸ“š Additional Resources

### Learning Materials
- [Selenium Documentation](https://www.selenium.dev/documentation/)
- [Pytest Documentation](https://docs.pytest.org/)
- [Page Object Model Pattern](https://www.selenium.dev/documentation/test_practices/encouraged/page_object_models/)
- [Python Testing Best Practices](https://docs.python-guide.org/writing/tests/)

### Related Projects
- [Selenium Examples](https://github.com/SeleniumHQ/selenium/tree/trunk/py/test)
- [pytest-selenium](https://github.com/pytest-dev/pytest-selenium)

---

**Last Updated:** December 2024

**Project Status:** âœ… Active | ğŸ“ˆ Continuously Improving

---

<div align="center">

### â­ If you find this project helpful, please consider giving it a star!

**Built with â¤ï¸ and modern development tools**

</div>